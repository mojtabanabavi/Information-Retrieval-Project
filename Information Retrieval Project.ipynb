{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "8Q-z5Fy5mi5T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pip install sklearn numpy pandas requests jdatetime bs4 newspaper3k google.colab"
      ],
      "outputs": [],
      "metadata": {
        "id": "A82jAdJ-mi5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "tdKla3f5mi5g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "import numpy\n",
        "import pandas\n",
        "import requests\n",
        "import jdatetime\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from newspaper import Article\n",
        "from google.colab import drive\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "outputs": [],
      "metadata": {
        "id": "iZP47Apxmi5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crawling"
      ],
      "metadata": {
        "id": "U9V_s7ySmi5j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "collected_data = []\n",
        "main_url = 'https://www.khabaronline.ir'\n",
        "\n",
        "def get_html_content(date, page):\n",
        "\n",
        "  date = date.strftime('%Y-%m-%d')\n",
        "  page_url = f'{main_url}/page/archive.xhtml?date={date}&pi={page}'\n",
        "\n",
        "  return requests.get(url= page_url).text\n",
        "\n",
        "def get_article_links(date, page):\n",
        "  \n",
        "  html_content = get_html_content(date= date, page= page)\n",
        "\n",
        "  html_parser = BeautifulSoup(markup= html_content, features= 'html.parser')\n",
        "\n",
        "  html_a_links = html_parser.select(selector= 'ul li.news h3 a')\n",
        "\n",
        "  article_links = []\n",
        "\n",
        "  for a_link in html_a_links:\n",
        "\n",
        "    article_links.append(a_link['href'])\n",
        "\n",
        "  return article_links\n",
        "\n",
        "def parse_article_content(url):\n",
        "\n",
        "  article_url = f'{main_url}{url}'\n",
        "\n",
        "  article = Article(url= article_url, language= 'fa')\n",
        "\n",
        "  article.download()\n",
        "\n",
        "  article.parse()\n",
        "  \n",
        "  article_content = {\n",
        "    'url': article.url,\n",
        "    'id': article.meta_data['nastooh']['nid'],\n",
        "    'title': article.title,\n",
        "    'image': article.top_img,\n",
        "    'summary': article.meta_description,\n",
        "    'text': article.text,\n",
        "    'tags': article.tags,\n",
        "    'publish': article.publish_date,\n",
        "    'keywords': article.meta_keywords,\n",
        "  }\n",
        "\n",
        "  return article_content\n",
        "\n",
        "def save_collected_data(current_date, from_date, to_date):\n",
        "\n",
        "  try:\n",
        "\n",
        "    df = pandas.DataFrame(data= collected_data)\n",
        "\n",
        "    from_date = from_date.strftime(\"%Y-%m-%d\")\n",
        "    to_date = to_date.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    data_file_name = f'khabaronline-{from_date}-{to_date}.csv'\n",
        "\n",
        "    df.to_csv(data_file_name, mode='a', index=False, header=False)\n",
        "\n",
        "    print(f'\\nAll colleted data in date: {current_date} has been saved.\\n')\n",
        "\n",
        "  except:\n",
        "    print(f'\\nSomething went wrong when trying to save colleted data in date: {current_date}.\\n')\n",
        "\n",
        "def crawl_khabaronline(from_date, to_date):\n",
        "  \n",
        "  page = 0\n",
        "  current_date = from_date\n",
        "\n",
        "  while True:\n",
        "\n",
        "    try:\n",
        "\n",
        "      page += 1\n",
        "      print(f'\\nCollecting articles in date: {current_date.strftime(\"%Y-%m-%d\")} and page: {page}:')\n",
        "      article_links = get_article_links(date= current_date, page= page)\n",
        "      \n",
        "      if len(article_links) != 0:\n",
        "\n",
        "        for article_url in article_links:\n",
        "\n",
        "          try:\n",
        "            article_content = parse_article_content(url= article_url)\n",
        "            print(f'\\tParsed article with id: {article_content[\"id\"]}')\n",
        "            collected_data.append(article_content)\n",
        "          except:\n",
        "            print(f'Something went wrong when trying to parse article with (article_url:{article_url}) parameters.')        \n",
        "            continue\n",
        "\n",
        "      else:\n",
        "        if current_date == to_date:\n",
        "          break\n",
        "        else:\n",
        "          page = 0\n",
        "          save_collected_data(current_date= current_date, from_date= from_date, to_date= to_date)\n",
        "          current_date = current_date + jdatetime.timedelta(days= 1)\n",
        "          collected_data.clear()\n",
        "\n",
        "    except:\n",
        "      print(f'Something went wrong when trying to get article links with (date:{current_date.strftime(\"%Y-%m-%d\")}, page: {page}) parameters.')    \n",
        "      continue"
      ],
      "outputs": [],
      "metadata": {
        "id": "wfxcMUh0mi5k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# usage\n",
        "\n",
        "from_date = jdatetime.date(year= 1400, month= 1, day= 1)\n",
        "to_date = jdatetime.date(year= 1400, month= 4, day= 31)\n",
        "\n",
        "crawl_khabaronline(from_date= from_date, to_date = to_date)"
      ],
      "outputs": [],
      "metadata": {
        "id": "iK4I1fNqmi5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading Collected Data"
      ],
      "metadata": {
        "id": "rjKsDPqGm3LD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data from google drive\n",
        "\n",
        "drive.mount(mountpoint= '/content/drive')\n",
        "\n",
        "data_file_path = '/content/drive/MyDrive/Colab Notebooks/khabaronline-1400-01-01-1400-04-31.csv'\n",
        "\n",
        "documents = pandas.read_csv(filepath_or_buffer= data_file_path)"
      ],
      "metadata": {
        "id": "B8ymeXrdp3Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA Collected Data"
      ],
      "metadata": {
        "id": "kNeFsi4Qqk4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shape (number of rows and columns)\n",
        "\n",
        "documents.shape"
      ],
      "metadata": {
        "id": "fbqsFSYJqosD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# column names\n",
        "\n",
        "documents.columns"
      ],
      "metadata": {
        "id": "FH0QQiIKqqAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top eight documents\n",
        "\n",
        "documents.head(8)"
      ],
      "metadata": {
        "id": "i8qa1q54HNKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tf-Idf Documents Vectorization"
      ],
      "metadata": {
        "id": "pU4AAn9ZrP9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "vectorized_documents = vectorizer.fit_transform(raw_documents= documents['summary'])"
      ],
      "metadata": {
        "id": "CRP_F7iurVam"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA Vectorized Documents"
      ],
      "metadata": {
        "id": "UnZ3sUFhwftf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shape (number of rows (documents) and columns (vocabulary))\n",
        "\n",
        "vectorized_documents.shape"
      ],
      "metadata": {
        "id": "Mo33sNAawlol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of tf-idf vocabulary\n",
        "\n",
        "len(vectorizer.vocabulary_)"
      ],
      "metadata": {
        "id": "QOo8SsvIwuzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top eight vocabulary words\n",
        "\n",
        "list(vectorizer.vocabulary_.keys())[:8]"
      ],
      "metadata": {
        "id": "uoUnxSeOwtOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tf-Idf Query Vectorization"
      ],
      "metadata": {
        "id": "-xtvzi3ztQVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'قیمت امروز دلار'\n",
        "\n",
        "vectorized_query = vectorizer.transform(raw_documents= [query])[0]"
      ],
      "metadata": {
        "id": "4Utx8a-ytSwe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating Similarities"
      ],
      "metadata": {
        "id": "vgWPvldty-qD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_document_similarities = []\n",
        "\n",
        "for document in vectorized_documents:\n",
        "  similarity = float(cosine_similarity(document, vectorized_query))\n",
        "  query_document_similarities.append(similarity)"
      ],
      "metadata": {
        "id": "aAg5D3BgzC9N"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sorting Results"
      ],
      "metadata": {
        "id": "KpVoyu2OzTPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_count = 20\n",
        "sorted_indexes = numpy.argsort(query_document_similarities)\n",
        "\n",
        "for i in range(result_count):\n",
        "  current_index = sorted_indexes[-i-1]\n",
        "  current_document = documents.iloc[current_index]\n",
        "  print('similarity:', query_document_similarities[current_index], 'title:', current_document['title'], 'url:', current_document['url'])"
      ],
      "metadata": {
        "id": "vT8rva0LPc4l"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.10.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.10.4 64-bit"
    },
    "interpreter": {
      "hash": "5022a729a0db21b119333491222278ec81b69f10ffcda59104c8c04c6b95be8d"
    },
    "colab": {
      "name": "Information-Retrieval-Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8Q-z5Fy5mi5T",
        "tdKla3f5mi5g",
        "U9V_s7ySmi5j",
        "rjKsDPqGm3LD",
        "kNeFsi4Qqk4r",
        "pU4AAn9ZrP9e",
        "UnZ3sUFhwftf",
        "-xtvzi3ztQVb"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}